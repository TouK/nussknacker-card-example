version: '3.8'

services:
  credit_card_model:
    container_name: nussknacker_fraud_credit_card_model
    hostname: credit_card_model
    build:
      context: ../model/serve
    ports:
      - "8001:80"
  geo_location:
    container_name: nussknacker_fraud_geo_location
    hostname: geo_location
    build:
      context: ../geo
    ports:
      - "5432:5432"
    environment:
      POSTGRES_PASSWORD: admin1
      POSTGRES_USER: geo-db
  data_generator:
    container_name: nussknacker_fraud_data_generator
    hostname: data_generator
    build:
      context: ../generator
    environment:
      KAFKA_ADDRESS: kafka:9092
      SCHEMA_REGISTRY_URL: http://schemaregistry:8081  


  designer:
    container_name: nussknacker_fraud_designer
    image: ${NUSSKNACKER_IMAGE-touk/nussknacker}:${NUSSKNACKER_VERSION-staging-latest}
    ports:
      - "3081:8080"
      - "3181:8181"  
    environment:
      #multiple, comma separated, config files can be used. They will be merged in order, via HOCON fallback mechanism
      #https://github.com/lightbend/config/blob/master/HOCON.md#config-object-merging-and-file-merging
      CONFIG_FILE: ${NUSSKNACKER_CONFIG_FILE-/opt/nussknacker/conf/application.conf,/opt/nussknacker/conf/nussknacker.conf}
      JDK_JAVA_OPTIONS: -Xmx1000M  -XX:+HeapDumpOnOutOfMemoryError
      DEFAULT_SCENARIO_TYPE: ${DEFAULT_SCENARIO_TYPE-streaming}
      INFLUXDB_URL: http://influxdb:8086
      OPENAPI_SERVICE_URL: http://customerservice:5000
      AUTO_OFFSET_RESET: ${AUTO_OFFSET_RESET-latest}
      FLINK_REST_URL: http://jobmanager:8081
      FLINK_QUERYABLE_STATE_PROXY_URL: taskmanager:9069
      KAFKA_ADDRESS: kafka:9092
      SCHEMA_REGISTRY_URL: http://schemaregistry:8081  
    volumes:
      #this is needed to be able to verify savepoints during deployments
      - storage_flink:/opt/flink/data
      - storage_designer:/opt/nussknacker/storage
      - ${BASE_PATH}/nussknacker/nussknacker.conf:/opt/nussknacker/conf/nussknacker.conf

  influxdb:
    container_name: nussknacker_fraud_influxdb
    hostname: influxdb
    image: influxdb:${INFLUXDB_VERSION-1.8.10}
    ports:
      - "3086:8086"
    environment:
      INFLUXDB_DB: esp
      INFLUXDB_DATA_QUERY_LOG_ENABLED: "false"
      INFLUXDB_HTTP_LOG_ENABLED: "false"
    volumes:
      - storage_influxdb:/var/lib/influxdb

  grafana:
    container_name: nussknacker_fraud_grafana
    image: grafana/grafana:${GRAFANA_VERSION-8.4.2}
    volumes:
      - ./grafana:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_SERVER_ROOT_URL=%(protocol)s://%(domain)s:/grafana
      - GF_SECURITY_ALLOW_EMBEDDING=true
    depends_on:
      - influxdb

  nginx:
    container_name: nussknacker_fraud_nginx
    image: nginx:${NGINX_VERSION-1.17.6}
    ports:
      - "${NGINX_PORT-8081}:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ${BASE_PATH}/nginx/additional:/etc/nginx/additional
    #we restart over 30s to let additional services (grafana, flink etc.) come up
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 6

  telegraf:
    container_name: nussknacker_fraud_telegraf
    image: telegraf:${TELEGRAF_VERSION-1.20.4}
    volumes:
      - ${BASE_PATH}/telegraf/telegraf.conf:/etc/telegraf/telegraf.conf

  zookeeper:
    container_name: nussknacker_fraud_zookeeper
    image: zookeeper:${ZOOKEEPER_VERSION-3.5.8}
    environment:
      ZOO_MY_ID: 1
      JVMFLAGS: "-Xms64m -Xmx128m"
      ZOO_4LW_COMMANDS_WHITELIST: "srvr,ruok"
    volumes:
      - storage_zookeeper_datalog:/datalog
      - storage_zookeeper_data:/data
    healthcheck:
      test: ["CMD-SHELL", 'echo "ruok" | nc -w 2 -q 2 localhost 2181 | grep imok']
      interval: 5s
      retries: 5

  kafka:
    container_name: nussknacker_fraud_kafka
    # It is used for kafka logs.dir - can't be randomly changed
    hostname: kafka
    image: ${KAFKA_REPOSITORY-wurstmeister/kafka}:${KAFKA_VERSION-2.13-2.8.1}
    ports:
      - "3032:3032"
    environment:
      HOSTNAME_COMMAND: "docker info | grep ^Name: | cut -d' ' -f 2"
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:3032
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://localhost:3032
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "transactions:1:1,alerts:1:1,processedEvents:1:1"
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_HEAP_OPTS: -Xms128m -Xmx512m
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - storage_kafka_data:/kafka
    healthcheck:
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic transactions --describe"]
      interval: 10s
      retries: 5
    depends_on:
      - zookeeper

  akhq:
    container_name: nussknacker_fraud_akhq
    image: tchiotludo/akhq:${AKHQ_VERSION-0.21.0}
    environment:
      AKHQ_CONFIGURATION: |
        micronaut:
          server:
            context-path: /akhq
        akhq:
          security:
            default-group: ${AKHQ_SECURITY_GROUP-admin}
          connections:
            nussknacker:
              properties:
                bootstrap.servers: "kafka:9092"
              schema-registry:
                url: "http://schemaregistry:8081"
    ports:
      - 8085:8080
    links:
      - kafka
      - schemaregistry

  schemaregistry:
    container_name: nussknacker_fraud_schemaregistry
    image: confluentinc/cp-schema-registry:${SCHEMA_REGISTRY_VERSION-7.2.1}
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:9092
      SCHEMA_REGISTRY_HOST_NAME: schemaregistry
    ports:
      - "3082:8081"
    depends_on:
      - kafka
    healthcheck:
      test: ["CMD-SHELL", "curl localhost:8081/subjects"]
      interval: 20s
      retries: 5

  jobmanager:
    container_name: nussknacker_fraud_jobmanager
    image: flink:${FLINK_VERSION-1.16.0}-scala_${SCALA_VERSION-2.12}-${JAVA_VERSION-java11}
    ports:
      - "3031:8081"
      - "9249:9249"
    entrypoint: /flink-entrypoint.sh
    command: jobmanager
    environment:
      # those environment variables are duplicated here and in designer service, in case of setup with designer run in other network than flink
      KAFKA_ADDRESS: kafka:9092
      SCHEMA_REGISTRY_URL: http://schemaregistry:8081
      OPENAPI_SERVICE_URL: http://customerservice:5000
      TASK_MANAGER_NUMBER_OF_TASK_SLOTS: 40
    depends_on:
      - zookeeper
      - kafka
      - influxdb
    volumes:
      - ${BASE_PATH}/flink/flink-conf.yaml:/tmp/flink-conf.yaml
      - ${BASE_PATH}/flink/log4j-console.properties:/opt/flink/conf/log4j-console.properties
      - ${BASE_PATH}/flink/flink-entrypoint.sh:/flink-entrypoint.sh
      # can be removed unless you use database enricher
      - ${BASE_PATH}/flink/postgresql-42.2.19.jar:/opt/flink/lib/postgresql-42.2.19.jar
      - storage_flink:/opt/flink/data

  taskmanager:
    container_name: nussknacker_fraud_taskmanager
    image: flink:${FLINK_VERSION-1.16.0}-scala_${SCALA_VERSION-2.12}-${JAVA_VERSION-java11}
    ports:
      - "3063:9069"
      - "9009:9009"
      - "9008:9008"
    entrypoint: /flink-entrypoint.sh
    command: taskmanager
    environment:
      TASK_MANAGER_NUMBER_OF_TASK_SLOTS: 40
    depends_on:
      - zookeeper
      - kafka
      - jobmanager
      - influxdb
    volumes:
      - ${BASE_PATH}/flink/flink-conf.yaml:/tmp/flink-conf.yaml
      - ${BASE_PATH}/flink/flink-entrypoint.sh:/flink-entrypoint.sh
      - ${BASE_PATH}/flink/log4j-console.properties:/opt/flink/conf/log4j-console.properties
      - storage_flink:/opt/flink/data
      # can be removed unless you use database enricher
      - ${BASE_PATH}/flink/postgresql-42.2.19.jar:/opt/flink/lib/postgresql-42.2.19.jar
    ulimits:
      nproc: 70000
      nofile:
        soft: 70000
        hard: 70000

volumes:
  storage_zookeeper_datalog:
    name: nussknacker_fraud_storage_zookeeper_datalog
  storage_zookeeper_data:
    name: nussknacker_fraud_storage_zookeeper_data
  storage_kafka_data:
    name: nussknacker_fraud_storage_kafka_data
  storage_flink:
    name: nussknacker_fraud_storage_flink
  storage_influxdb:
    name: nussknacker_fraud_storage_influxdb
  storage_designer:
    name: nussknacker_fraud_storage_designer

networks:
  default:
    name: nussknacker_fraud_network
